{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "import cv2\n",
    "from deepface import DeepFace\n",
    "from mtcnn import MTCNN\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "from tkinter import ttk\n",
    "from tkinter import Tk, filedialog\n",
    "from PIL import Image,ImageTk\n",
    "#import subprocess\n",
    "#import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function For Face Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function For Face Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face detection button clicked\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "6/6 [==============================] - 1s 8ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "Face recognition button clicked\n",
      "images image_0.jpg\n",
      "file C:/Users/lab/Desktop/Final - Project/detect_faces\\image_0.jpg\n",
      "{'verified': False, 'distance': 0.833067668240816, 'threshold': 0.68, 'model': 'VGG-Face', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 0, 'y': 0, 'w': 224, 'h': 224, 'left_eye': None, 'right_eye': None}, 'img2': {'x': 0, 'y': 0, 'w': 485, 'h': 662, 'left_eye': None, 'right_eye': None}}, 'time': 1.68}\n",
      "{'verified': False, 'distance': 0.9426298982986209, 'threshold': 0.68, 'model': 'VGG-Face', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 0, 'y': 0, 'w': 224, 'h': 224, 'left_eye': None, 'right_eye': None}, 'img2': {'x': 261, 'y': 146, 'w': 379, 'h': 379, 'left_eye': (379, 295), 'right_eye': (510, 298)}}, 'time': 1.57}\n",
      "{'verified': False, 'distance': 0.9207461052392321, 'threshold': 0.68, 'model': 'VGG-Face', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 0, 'y': 0, 'w': 224, 'h': 224, 'left_eye': None, 'right_eye': None}, 'img2': {'x': 59, 'y': 253, 'w': 354, 'h': 354, 'left_eye': (171, 392), 'right_eye': (295, 388)}}, 'time': 1.51}\n",
      "{'verified': False, 'distance': 0.8318924279652364, 'threshold': 0.68, 'model': 'VGG-Face', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 0, 'y': 0, 'w': 224, 'h': 224, 'left_eye': None, 'right_eye': None}, 'img2': {'x': 28, 'y': 27, 'w': 310, 'h': 310, 'left_eye': (125, 150), 'right_eye': (187, 155)}}, 'time': 1.47}\n",
      "{'verified': True, 'distance': -4.440892098500626e-16, 'threshold': 0.68, 'model': 'VGG-Face', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 0, 'y': 0, 'w': 224, 'h': 224, 'left_eye': None, 'right_eye': None}, 'img2': {'x': 0, 'y': 0, 'w': 224, 'h': 224, 'left_eye': None, 'right_eye': None}}, 'time': 1.39}\n",
      "detected\n",
      "None\n",
      "images image_1.jpg\n",
      "file C:/Users/lab/Desktop/Final - Project/detect_faces\\image_1.jpg\n",
      "{'verified': False, 'distance': 0.9087060221399568, 'threshold': 0.68, 'model': 'VGG-Face', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 0, 'y': 0, 'w': 224, 'h': 224, 'left_eye': None, 'right_eye': None}, 'img2': {'x': 0, 'y': 0, 'w': 485, 'h': 662, 'left_eye': None, 'right_eye': None}}, 'time': 1.4}\n",
      "{'verified': False, 'distance': 0.8593458520156161, 'threshold': 0.68, 'model': 'VGG-Face', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 0, 'y': 0, 'w': 224, 'h': 224, 'left_eye': None, 'right_eye': None}, 'img2': {'x': 261, 'y': 146, 'w': 379, 'h': 379, 'left_eye': (379, 295), 'right_eye': (510, 298)}}, 'time': 1.48}\n",
      "{'verified': False, 'distance': 0.9606779529252145, 'threshold': 0.68, 'model': 'VGG-Face', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 0, 'y': 0, 'w': 224, 'h': 224, 'left_eye': None, 'right_eye': None}, 'img2': {'x': 59, 'y': 253, 'w': 354, 'h': 354, 'left_eye': (171, 392), 'right_eye': (295, 388)}}, 'time': 1.42}\n",
      "{'verified': True, 'distance': 0.10220718698044862, 'threshold': 0.68, 'model': 'VGG-Face', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 0, 'y': 0, 'w': 224, 'h': 224, 'left_eye': None, 'right_eye': None}, 'img2': {'x': 28, 'y': 27, 'w': 310, 'h': 310, 'left_eye': (125, 150), 'right_eye': (187, 155)}}, 'time': 1.41}\n",
      "detected\n",
      "None\n",
      "{'verified': False, 'distance': 0.8109568785847259, 'threshold': 0.68, 'model': 'VGG-Face', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 0, 'y': 0, 'w': 224, 'h': 224, 'left_eye': None, 'right_eye': None}, 'img2': {'x': 0, 'y': 0, 'w': 224, 'h': 224, 'left_eye': None, 'right_eye': None}}, 'time': 1.34}\n",
      "images image_2.jpg\n",
      "file C:/Users/lab/Desktop/Final - Project/detect_faces\\image_2.jpg\n",
      "{'verified': False, 'distance': 0.8363243047107727, 'threshold': 0.68, 'model': 'VGG-Face', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 0, 'y': 0, 'w': 224, 'h': 224, 'left_eye': None, 'right_eye': None}, 'img2': {'x': 0, 'y': 0, 'w': 485, 'h': 662, 'left_eye': None, 'right_eye': None}}, 'time': 1.43}\n",
      "{'verified': False, 'distance': 0.9133301539350784, 'threshold': 0.68, 'model': 'VGG-Face', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 0, 'y': 0, 'w': 224, 'h': 224, 'left_eye': None, 'right_eye': None}, 'img2': {'x': 261, 'y': 146, 'w': 379, 'h': 379, 'left_eye': (379, 295), 'right_eye': (510, 298)}}, 'time': 1.49}\n",
      "{'verified': False, 'distance': 0.9593066394375193, 'threshold': 0.68, 'model': 'VGG-Face', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 0, 'y': 0, 'w': 224, 'h': 224, 'left_eye': None, 'right_eye': None}, 'img2': {'x': 59, 'y': 253, 'w': 354, 'h': 354, 'left_eye': (171, 392), 'right_eye': (295, 388)}}, 'time': 1.54}\n",
      "{'verified': False, 'distance': 0.8651293653501341, 'threshold': 0.68, 'model': 'VGG-Face', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 0, 'y': 0, 'w': 224, 'h': 224, 'left_eye': None, 'right_eye': None}, 'img2': {'x': 28, 'y': 27, 'w': 310, 'h': 310, 'left_eye': (125, 150), 'right_eye': (187, 155)}}, 'time': 1.42}\n",
      "{'verified': False, 'distance': 0.7161395595609787, 'threshold': 0.68, 'model': 'VGG-Face', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 0, 'y': 0, 'w': 224, 'h': 224, 'left_eye': None, 'right_eye': None}, 'img2': {'x': 0, 'y': 0, 'w': 224, 'h': 224, 'left_eye': None, 'right_eye': None}}, 'time': 1.37}\n",
      "images image_3.jpg\n",
      "file C:/Users/lab/Desktop/Final - Project/detect_faces\\image_3.jpg\n",
      "{'verified': False, 'distance': 0.829078387175764, 'threshold': 0.68, 'model': 'VGG-Face', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 0, 'y': 0, 'w': 224, 'h': 224, 'left_eye': None, 'right_eye': None}, 'img2': {'x': 0, 'y': 0, 'w': 485, 'h': 662, 'left_eye': None, 'right_eye': None}}, 'time': 1.44}\n",
      "{'verified': False, 'distance': 0.8011338627289992, 'threshold': 0.68, 'model': 'VGG-Face', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 0, 'y': 0, 'w': 224, 'h': 224, 'left_eye': None, 'right_eye': None}, 'img2': {'x': 261, 'y': 146, 'w': 379, 'h': 379, 'left_eye': (379, 295), 'right_eye': (510, 298)}}, 'time': 1.46}\n",
      "{'verified': False, 'distance': 0.9308519067737349, 'threshold': 0.68, 'model': 'VGG-Face', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 0, 'y': 0, 'w': 224, 'h': 224, 'left_eye': None, 'right_eye': None}, 'img2': {'x': 59, 'y': 253, 'w': 354, 'h': 354, 'left_eye': (171, 392), 'right_eye': (295, 388)}}, 'time': 1.49}\n",
      "{'verified': False, 'distance': 0.825807214783613, 'threshold': 0.68, 'model': 'VGG-Face', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 0, 'y': 0, 'w': 224, 'h': 224, 'left_eye': None, 'right_eye': None}, 'img2': {'x': 28, 'y': 27, 'w': 310, 'h': 310, 'left_eye': (125, 150), 'right_eye': (187, 155)}}, 'time': 1.44}\n",
      "{'verified': False, 'distance': 0.8839665694893309, 'threshold': 0.68, 'model': 'VGG-Face', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 0, 'y': 0, 'w': 224, 'h': 224, 'left_eye': None, 'right_eye': None}, 'img2': {'x': 0, 'y': 0, 'w': 224, 'h': 224, 'left_eye': None, 'right_eye': None}}, 'time': 1.4}\n",
      "images image_4.jpg\n",
      "file C:/Users/lab/Desktop/Final - Project/detect_faces\\image_4.jpg\n",
      "{'verified': False, 'distance': 0.7950349160254508, 'threshold': 0.68, 'model': 'VGG-Face', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 0, 'y': 0, 'w': 224, 'h': 224, 'left_eye': None, 'right_eye': None}, 'img2': {'x': 0, 'y': 0, 'w': 485, 'h': 662, 'left_eye': None, 'right_eye': None}}, 'time': 1.46}\n",
      "{'verified': False, 'distance': 0.9595672727071111, 'threshold': 0.68, 'model': 'VGG-Face', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 0, 'y': 0, 'w': 224, 'h': 224, 'left_eye': None, 'right_eye': None}, 'img2': {'x': 261, 'y': 146, 'w': 379, 'h': 379, 'left_eye': (379, 295), 'right_eye': (510, 298)}}, 'time': 1.46}\n",
      "{'verified': False, 'distance': 0.9454782865185806, 'threshold': 0.68, 'model': 'VGG-Face', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 0, 'y': 0, 'w': 224, 'h': 224, 'left_eye': None, 'right_eye': None}, 'img2': {'x': 59, 'y': 253, 'w': 354, 'h': 354, 'left_eye': (171, 392), 'right_eye': (295, 388)}}, 'time': 1.47}\n",
      "{'verified': False, 'distance': 0.9188310652408131, 'threshold': 0.68, 'model': 'VGG-Face', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 0, 'y': 0, 'w': 224, 'h': 224, 'left_eye': None, 'right_eye': None}, 'img2': {'x': 28, 'y': 27, 'w': 310, 'h': 310, 'left_eye': (125, 150), 'right_eye': (187, 155)}}, 'time': 1.44}\n",
      "{'verified': False, 'distance': 0.7570164739642634, 'threshold': 0.68, 'model': 'VGG-Face', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 0, 'y': 0, 'w': 224, 'h': 224, 'left_eye': None, 'right_eye': None}, 'img2': {'x': 0, 'y': 0, 'w': 224, 'h': 224, 'left_eye': None, 'right_eye': None}}, 'time': 1.35}\n",
      "[[[253 255 255]\n",
      "  [253 255 255]\n",
      "  [252 254 254]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [251 249 249]]\n",
      "\n",
      " [[247 252 253]\n",
      "  [248 253 254]\n",
      "  [250 255 255]\n",
      "  ...\n",
      "  [252 254 254]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[243 255 255]\n",
      "  [243 255 255]\n",
      "  [243 255 255]\n",
      "  ...\n",
      "  [251 253 253]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 12  15  23]\n",
      "  [ 38  41  49]\n",
      "  [ 26  29  37]\n",
      "  ...\n",
      "  [249 254 255]\n",
      "  [253 255 255]\n",
      "  [254 254 254]]\n",
      "\n",
      " [[  0   3  11]\n",
      "  [ 16  19  27]\n",
      "  [ 19  22  30]\n",
      "  ...\n",
      "  [249 254 255]\n",
      "  [253 255 255]\n",
      "  [254 254 254]]\n",
      "\n",
      " [[  6   9  17]\n",
      "  [  3   6  14]\n",
      "  [  2   5  13]\n",
      "  ...\n",
      "  [250 255 255]\n",
      "  [253 255 255]\n",
      "  [254 254 254]]]\n",
      "{'verified': False, 'distance': 1.2911084215205297, 'threshold': 0.8, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'euclidean_l2', 'facial_areas': {'img1': {'x': 880, 'y': 525, 'w': 155, 'h': 155, 'left_eye': (925, 584), 'right_eye': (990, 583)}, 'img2': {'x': 0, 'y': 0, 'w': 485, 'h': 662, 'left_eye': None, 'right_eye': None}}, 'time': 0.87}\n",
      "Faces do not match.\n",
      "[[[157 155 154]\n",
      "  [157 155 154]\n",
      "  [157 155 154]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[157 155 154]\n",
      "  [157 155 154]\n",
      "  [157 155 154]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[157 155 154]\n",
      "  [157 155 154]\n",
      "  [157 155 154]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 91  93  94]\n",
      "  [ 91  93  94]\n",
      "  [ 91  93  94]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [252 252 252]\n",
      "  [248 248 248]]\n",
      "\n",
      " [[253 255 255]\n",
      "  [253 255 255]\n",
      "  [253 255 255]\n",
      "  ...\n",
      "  [254 254 254]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[252 254 255]\n",
      "  [252 254 255]\n",
      "  [252 254 255]\n",
      "  ...\n",
      "  [253 253 253]\n",
      "  [252 252 252]\n",
      "  [250 250 250]]]\n",
      "{'verified': False, 'distance': 1.3247924984525161, 'threshold': 0.8, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'euclidean_l2', 'facial_areas': {'img1': {'x': 880, 'y': 525, 'w': 155, 'h': 155, 'left_eye': (925, 584), 'right_eye': (990, 583)}, 'img2': {'x': 261, 'y': 146, 'w': 379, 'h': 379, 'left_eye': (379, 295), 'right_eye': (510, 298)}}, 'time': 0.82}\n",
      "Faces do not match.\n",
      "[[[145 153 152]\n",
      "  [145 153 152]\n",
      "  [145 153 152]\n",
      "  ...\n",
      "  [109 118 131]\n",
      "  [108 117 130]\n",
      "  [108 117 130]]\n",
      "\n",
      " [[145 153 152]\n",
      "  [145 153 152]\n",
      "  [145 153 152]\n",
      "  ...\n",
      "  [109 118 131]\n",
      "  [109 118 131]\n",
      "  [109 118 131]]\n",
      "\n",
      " [[145 153 152]\n",
      "  [145 153 152]\n",
      "  [145 153 152]\n",
      "  ...\n",
      "  [109 118 131]\n",
      "  [109 118 131]\n",
      "  [109 118 131]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 50  64  87]\n",
      "  [ 50  64  87]\n",
      "  [ 50  63  89]\n",
      "  ...\n",
      "  [ 45  44  46]\n",
      "  [ 47  46  48]\n",
      "  [ 50  47  49]]\n",
      "\n",
      " [[ 43  57  80]\n",
      "  [ 42  56  79]\n",
      "  [ 44  58  81]\n",
      "  ...\n",
      "  [ 45  44  46]\n",
      "  [ 46  45  47]\n",
      "  [ 48  45  47]]\n",
      "\n",
      " [[ 39  53  76]\n",
      "  [ 37  51  74]\n",
      "  [ 39  53  76]\n",
      "  ...\n",
      "  [ 45  44  46]\n",
      "  [ 46  45  47]\n",
      "  [ 48  45  47]]]\n",
      "{'verified': False, 'distance': 1.325950334839856, 'threshold': 0.8, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'euclidean_l2', 'facial_areas': {'img1': {'x': 880, 'y': 525, 'w': 155, 'h': 155, 'left_eye': (925, 584), 'right_eye': (990, 583)}, 'img2': {'x': 59, 'y': 253, 'w': 354, 'h': 354, 'left_eye': (171, 392), 'right_eye': (295, 388)}}, 'time': 0.83}\n",
      "Faces do not match.\n",
      "[[[253 253 253]\n",
      "  [227 227 227]\n",
      "  [240 240 240]\n",
      "  ...\n",
      "  [241 241 241]\n",
      "  [240 240 240]\n",
      "  [253 253 253]]\n",
      "\n",
      " [[214 214 214]\n",
      "  [  0   0   0]\n",
      "  [  0   0   0]\n",
      "  ...\n",
      "  [  0   0   0]\n",
      "  [  0   0   0]\n",
      "  [227 227 227]]\n",
      "\n",
      " [[  0   0   0]\n",
      "  [  0   0   0]\n",
      "  [132 139 153]\n",
      "  ...\n",
      "  [ 82 113 108]\n",
      "  [ 77 107 102]\n",
      "  [240 240 240]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]]\n",
      "{'verified': False, 'distance': 1.2581543445630474, 'threshold': 0.8, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'euclidean_l2', 'facial_areas': {'img1': {'x': 880, 'y': 525, 'w': 155, 'h': 155, 'left_eye': (925, 584), 'right_eye': (990, 583)}, 'img2': {'x': 28, 'y': 27, 'w': 310, 'h': 310, 'left_eye': (125, 150), 'right_eye': (187, 155)}}, 'time': 0.77}\n",
      "Faces do not match.\n",
      "[[[28 27 31]\n",
      "  [28 27 31]\n",
      "  [28 27 29]\n",
      "  ...\n",
      "  [68 67 69]\n",
      "  [68 67 69]\n",
      "  [67 66 68]]\n",
      "\n",
      " [[28 27 31]\n",
      "  [28 27 31]\n",
      "  [28 27 29]\n",
      "  ...\n",
      "  [68 67 69]\n",
      "  [68 67 69]\n",
      "  [67 66 68]]\n",
      "\n",
      " [[28 27 31]\n",
      "  [28 27 31]\n",
      "  [28 27 29]\n",
      "  ...\n",
      "  [66 65 67]\n",
      "  [66 65 67]\n",
      "  [66 65 67]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[78 69 65]\n",
      "  [78 69 65]\n",
      "  [77 68 64]\n",
      "  ...\n",
      "  [64 76 80]\n",
      "  [63 75 79]\n",
      "  [61 74 76]]\n",
      "\n",
      " [[84 75 71]\n",
      "  [82 73 69]\n",
      "  [81 72 68]\n",
      "  ...\n",
      "  [65 77 79]\n",
      "  [64 76 78]\n",
      "  [63 75 75]]\n",
      "\n",
      " [[85 76 72]\n",
      "  [83 74 70]\n",
      "  [81 72 68]\n",
      "  ...\n",
      "  [64 76 78]\n",
      "  [64 76 76]\n",
      "  [63 75 75]]]\n",
      "{'verified': False, 'distance': 1.4450015884721525, 'threshold': 0.8, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'euclidean_l2', 'facial_areas': {'img1': {'x': 880, 'y': 525, 'w': 155, 'h': 155, 'left_eye': (925, 584), 'right_eye': (990, 583)}, 'img2': {'x': 0, 'y': 0, 'w': 224, 'h': 224, 'left_eye': None, 'right_eye': None}}, 'time': 0.71}\n",
      "Faces do not match.\n"
     ]
    }
   ],
   "source": [
    "root1 = tk.Tk()\n",
    "root1.title(\"Face Recognition Landing Page\")\n",
    "\n",
    "# Set the background color\n",
    "root1.configure(bg='#f8f8f8')\n",
    "\n",
    "# Create a frame for the content\n",
    "content_frame = ttk.Frame(root1, padding=20)\n",
    "content_frame.pack(expand=True, fill='both')\n",
    "\n",
    "# Add the hand holding smartphone image\n",
    "filename = 'logo.jpg'\n",
    "image = Image.open(filename)\n",
    "\n",
    "tk_image = ImageTk.PhotoImage(image)\n",
    "\n",
    "hand_phone_label = ttk.Label(content_frame, image=tk_image, background='#f8f8f8')\n",
    "hand_phone_label.pack(pady=20)\n",
    "\n",
    "# Add the title\n",
    "title_label = ttk.Label(content_frame, text=\"Smart Eye\", font=('Arial', 24, 'bold'), background='#f8f8f8')\n",
    "title_label.pack(pady=10)\n",
    "\n",
    "# Add the subtitle\n",
    "subtitle_label = ttk.Label(content_frame, text=\"Experience the future of security\", font=('Arial', 16), background='#f8f8f8')\n",
    "subtitle_label.pack(pady=20)\n",
    "\n",
    "# Add the \"Get Started\" button\n",
    "def get_started():\n",
    "    \n",
    "    root1.destroy()\n",
    "    \n",
    "    root = tk.Tk()\n",
    "    \n",
    "    root.title(\"Face Recognition System\")\n",
    "                    \n",
    "\n",
    "    def detect_faces():\n",
    "             print(\"Face detection button clicked\")\n",
    "             canvas1.delete(\"all\")\n",
    "             if not os.path.exists(\"detect_faces\"):\n",
    "                      os.makedirs(\"detect_faces\")\n",
    "             camera = cv2.VideoCapture(0)\n",
    "             if camera.isOpened():\n",
    "                ret, pixels = camera.read()\n",
    "                if ret:\n",
    "                    detector = MTCNN()\n",
    "                    faces = detector.detect_faces(pixels)\n",
    "                    print(faces)\n",
    "                    \n",
    "                    current_frame = cv2.cvtColor(pixels, cv2.COLOR_BGR2RGB)\n",
    "                    photo = ImageTk.PhotoImage(image=Image.fromarray(current_frame))\n",
    "                    canvas1.create_image(0, 0, image=photo, anchor=tk.NW)\n",
    "                    canvas1.image = photo\n",
    "                    camera.release()\n",
    "             else:\n",
    "                filename=filedialog.askopenfilename()\n",
    "                #filename = 'image.jpg'\n",
    "                image = Image.open(filename)\n",
    "             \n",
    "                tk_image = ImageTk.PhotoImage(image)\n",
    "             \n",
    "                canvas1.create_image(0, 0, anchor=tk.NW, image=tk_image)\n",
    "                canvas1.image = tk_image\n",
    "                # load image from file\n",
    "                pixels = cv2.imread(filename)\n",
    "                # create the detector, using default weights\n",
    "                detector = MTCNN()\n",
    "                # detect faces in the image\n",
    "                faces = detector.detect_faces(pixels)\n",
    "                #To save the detectd faces\n",
    "                global face_array\n",
    "                global df\n",
    "                \n",
    "             def save_detect_faces(filename, result_list):\n",
    "                    \n",
    "                    i=0\n",
    " \n",
    "                    for result in result_list:\n",
    "        \n",
    "                             \n",
    "                            # get coordinates\n",
    "\n",
    "                             x, y, width, height = result['box']\n",
    "                             x2, y2 = x + width, y + height\n",
    "                             canvas1.create_rectangle(x, y, x2, y2, outline='red', width=2)\n",
    "                             \n",
    "                             face = filename[y:y2, x:x2]\n",
    "                             image = Image.fromarray(face)\n",
    "                             image = image.resize((224,224))\n",
    "                             face_array = asarray(image)\n",
    "    \n",
    "                             file_name = f'image_{i}.jpg'  # Generate a different file name for each image\n",
    "                            \n",
    "                             file_path = os.path.join('detect_faces', file_name)\n",
    "   \n",
    "    \n",
    "                             cv2.imwrite(file_path,face_array)\n",
    "    \n",
    " \n",
    "   \n",
    "                             i=i+1\n",
    "             save_detect_faces(pixels,faces)\n",
    "             \n",
    "\n",
    "    def recognize_faces():\n",
    "            print(\"Face recognition button clicked\")\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            #folder_dir = \"detect_faces\"\n",
    "            messagebox.showinfo(\"Select Folder 'detect_faces'\",\"Select detect_faces\")\n",
    "            folder_dir=filedialog.askdirectory(title=\"Select detect_faces Folder\")\n",
    "            messagebox.showinfo(\"Select Folder 'Database' \",\"Select Database\")\n",
    "            folder = filedialog.askdirectory(title=\"Select Folder\")\n",
    "            detected=[]\n",
    "            not_detected=[]\n",
    "            for images in os.listdir(folder_dir):\n",
    " \n",
    "           # check if the image ends with png\n",
    "                  print('images',images)\n",
    "                  file = os.path.join(folder_dir, images)\n",
    "                  print('file',file)\n",
    "                  x=cv2.imread(file)\n",
    "        \n",
    "                  \n",
    "                  for images1 in os.listdir(folder):\n",
    "                \n",
    "                \n",
    "                     \n",
    "               \n",
    "                      file_path = os.path.join(folder, images1)\n",
    "                      y=cv2.imread(file_path)\n",
    "                      type(y)\n",
    "                      type(x)\n",
    "                      result = DeepFace.verify(img1_path = x,img2_path = y,enforce_detection=False)\n",
    "                      print(result)\n",
    "                      i=0\n",
    "                      if result['verified']==True:\n",
    "                   \n",
    "                        \n",
    "                          messagebox.showinfo(\"showinfo\", f\"Match Found With{images1} \")\n",
    "                          print('detected')\n",
    "                    \n",
    "                    \n",
    "                          print(detected.append(file_path))\n",
    "                    \n",
    "            for k in detected:\n",
    "                image = Image.open(k)\n",
    "                image = image.resize((300, 300))\n",
    "                photo = ImageTk.PhotoImage(image)\n",
    "                label = tk.Label(canvas2, image=photo)\n",
    "                label.image = photo \n",
    "                label_id = canvas2.create_window(i, 0, anchor=tk.NW, window=label)\n",
    "               \n",
    "                i += image.width\n",
    "                      \n",
    "                i=i+1\n",
    "                \n",
    "    def liveness():  \n",
    "   \n",
    "\n",
    "   \n",
    "    # Load images\n",
    "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
    "        folder = filedialog.askdirectory(title=\"Select Folder\")\n",
    "        \n",
    "        pan_card_image = cv2.imread(\"Pan-Card.jpg\")\n",
    "        \n",
    "        for images in os.listdir(folder):\n",
    " \n",
    "           # check if the image ends with png\n",
    "        \n",
    "           file = os.path.join(folder, images)\n",
    "           x=cv2.imread(file) \n",
    "           print(x)\n",
    "           \n",
    "\n",
    "    # Perform face recognition\n",
    "           result = DeepFace.verify(pan_card_image, x, model_name='Facenet', distance_metric='euclidean_l2',enforce_detection=False)\n",
    "           print(result)\n",
    "\n",
    "         # Check if faces match\n",
    "           if result['verified']:\n",
    "                messagebox.showinfo(\"showinfo\", f\"Match found with {x}\")\n",
    "                image = Image.open(x)\n",
    "                image = image.resize((300, 300))\n",
    "                photo = ImageTk.PhotoImage(image)\n",
    "                label = tk.Label(canvas2, image=photo)\n",
    "                label.image = photo \n",
    "                label_id = canvas3.create_window(i, 0, anchor=tk.NW, window=label)\n",
    "               \n",
    "                print(\"Faces match.\")\n",
    "           else:\n",
    "               messagebox.showinfo(\"showinfo\", \"Match Not Found\")\n",
    "               print(\"Faces do not match.\")\n",
    "    def Help():\n",
    "        pass\n",
    "    \n",
    "    def Subscribe():\n",
    "        pass\n",
    "\n",
    "    def About():\n",
    "        Pass\n",
    "   # Main Section Frame with Face Detection and Recognition Buttons\n",
    "\n",
    "\n",
    "    left_frame = tk.Frame(root, width=200, height=400, bg='bisque2')\n",
    "    left_frame.pack(side='left', fill='both',expand=True)\n",
    "\n",
    "    middle_frame = tk.Frame(root, width=100, height=400, bg='PeachPuff2')\n",
    "    middle_frame.pack(side='left',  fill='both',expand=True)\n",
    "\n",
    "    right_frame = tk.Frame(root, width=200, height=400, bg='bisque2')\n",
    "    right_frame.pack(side='left',  fill='both',expand=True)\n",
    "\n",
    "    canvas1 = tk.Canvas(right_frame, width=600, height=250, bg='white')\n",
    "    canvas1.pack(pady=10)\n",
    "\n",
    "    detect_button = ttk.Button(middle_frame, text=\"Detect Faces\", command=detect_faces)\n",
    "    detect_button.place(x=10,y=100)\n",
    "\n",
    "    canvas2 = tk.Canvas(right_frame, width=600, height=250, bg='white')\n",
    "    canvas2.pack(pady=10)\n",
    "\n",
    "    recognize_button = ttk.Button(middle_frame, text=\"Recognize Faces\", command=recognize_faces)\n",
    "    recognize_button.place(x=10,y=400)\n",
    " \n",
    "\n",
    "    canvas3 = tk.Canvas(right_frame, width=600, height=250, bg='white')\n",
    "    canvas3.pack(pady=10)\n",
    "\n",
    "    Card_Biometric = ttk.Button(middle_frame, text=\"Card Biometric \", command=liveness)\n",
    "    Card_Biometric.place(x=10,y=600)\n",
    "\n",
    "    About=ttk.Button(left_frame, text=\"How To Use\", command=About)\n",
    "    About.place(x=10,y=50)\n",
    "    \n",
    "    \n",
    "    Help=ttk.Button(left_frame, text=\"Subscribe??\", command=Help)\n",
    "    Help.place(x=10,y=200)\n",
    "    \n",
    "    \n",
    "    Subscribe= ttk.Button(left_frame, text=\"About Us\", command=Subscribe)\n",
    "    Subscribe.place(x=10,y=400)\n",
    "    \n",
    "\n",
    "\n",
    "    root.mainloop()\n",
    "\n",
    "   \n",
    "    \n",
    "get_started_button = ttk.Button(content_frame, text=\"Get Started\", command=get_started, style='Colorful.TButton')\n",
    "get_started_button.pack()\n",
    "\n",
    "# Style the button\n",
    "s = ttk.Style()\n",
    "s.configure('Colorful.TButton', background='#007bff', foreground='white', font=('Arial', 12, 'bold'), padding=(10, 5))\n",
    "\n",
    "\n",
    "root1.mainloop()\n",
    "\n",
    "root1.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
